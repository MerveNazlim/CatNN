{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from util import *\n",
    "from load_data import load_input_file, build_combined_input\n",
    "from NN_train import *\n",
    "path_tosave = 'Models/1stDiscoModel'\n",
    "features_to_ignore = []\n",
    "#features_to_ignore = [\"DPhill_SS\"]\n",
    "features_to_ignore = [\"DRll01\",\"HT_jets\",\"sumPsbtag\",\"met_met\",\"Mll01\",\"DEtall_SS\", \"jet_pseudoscore_DL1r2\",\"nJets_OR_DL1r_77\",\"sumPsbtag77\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring feature:  DRll01\n",
      "Ignoring feature:  HT_jets\n",
      "Ignoring feature:  sumPsbtag\n",
      "Ignoring feature:  met_met\n",
      "Ignoring feature:  Mll01\n",
      "Ignoring feature:  DEtall_SS\n",
      "Ignoring feature:  jet_pseudoscore_DL1r2\n",
      "Ignoring feature:  nJets_OR_DL1r_77\n",
      "Ignoring feature:  sumPsbtag77\n",
      "Found 17 features on the dataset 8 features were loaded: \n",
      "\n",
      "DPhill_SS\n",
      "HT_lep\n",
      "MtLepMet\n",
      "jet_pseudoscore_DL1r0\n",
      "jet_pseudoscore_DL1r1\n",
      "jet_pt0_nofwd\n",
      "nJets_OR\n",
      "randomRunNumber\n",
      " \n",
      "Dataset contains extra labels for different backgrounds!\n",
      "Class 0  :  679239\n",
      "Class 1  :  231587\n",
      "Class 2  :  3249\n",
      "Class 3  :  310859\n",
      "Class 4  :  190589\n",
      "Class 5  :  223033\n",
      "Class 6  :  355647\n",
      "Class 7  :  109991\n",
      "Class 8  :  1039\n",
      "Dataset contains 679239 Signal events and 1425994 Background events.\n"
     ]
    }
   ],
   "source": [
    "samples, feature_names, class_names, class_no = load_input_file('data/sstt_multiclass_background_V03.h5', features_to_ignore)\n",
    "input_features, targets, class_labels, weights = build_combined_input(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DPhi = np.squeeze(input_features[:,0:1])\n",
    "Number = np.squeeze((input_features[:,7:8]).astype(int))\n",
    "#Number = np.arange(0,1679947)\n",
    "feature_names = feature_names[1:7]\n",
    "input_features = input_features[:,1:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['signal' 'ttZ' 'tty' 'ttW' 'tttt' 'ttH' 'Other' 'Diboson' 'Fakes']\n",
      "[0 1 2 3 4 5 6 7 8]\n"
     ]
    }
   ],
   "source": [
    "index_sort = np.argsort(class_no)\n",
    "class_names = (np.array(class_names)[index_sort])\n",
    "class_no = np.sort(class_no)\n",
    "print(class_names)\n",
    "print(class_no)\n",
    "No_Classes = class_no.max()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======Weight Statistic========================================\n",
      "Weights::        W(1)=1200.48, W(0)=2983.69\n",
      "Scaled weights:: W(1)=1.05262e+06, W(0)=1.05262e+06\n",
      "==============================================================\n"
     ]
    }
   ],
   "source": [
    "ScaleWeights(targets,weights)\n",
    "#scale the input between 0-1\n",
    "scaler = StandardScaler().fit(input_features)\n",
    "input_scaled = scaler.transform(input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fold_Odd_Even(input, targets, weights, class_labels, Number, Dphi):\n",
    "    input_odd = input[Number % 2 == 1]\n",
    "    targets_odd = targets[Number % 2 == 1]\n",
    "    weights_odd = weights[Number % 2 == 1]\n",
    "    class_labels_odd = class_labels[Number % 2 == 1]\n",
    "    input_even = input[Number % 2 == 0]\n",
    "    targets_even = targets[Number % 2 == 0]\n",
    "    weights_even = weights[Number % 2 == 0]\n",
    "    class_labels_even = class_labels[Number % 2 == 0]\n",
    "    Dphi_even = Dphi[Number % 2 == 0]\n",
    "    Dphi_odd = Dphi[Number % 2 == 1]\n",
    "    return (input_odd, targets_odd, weights_odd, class_labels_odd, Dphi_odd), (input_even, targets_even, weights_even, class_labels_even, Dphi_even)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "odd, even = Fold_Odd_Even(input_scaled, targets, weights, class_labels, Number, DPhi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train, val, test = Train_Val_Test_Split(input_scaled, targets, weights, class_labels)\n",
    "input_shape = odd[0].shape[1]\n",
    "n_epochs = 30\n",
    "batch_size = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_Model_with_Disco(input_shape):\n",
    "    layer_opts = dict( activation = 'sigmoid', kernel_initializer = initializers.glorot_normal(seed=seed))\n",
    "    Dphi_and_weight = Kl.Input(shape = (2,))\n",
    "    input_layer = Kl.Input(shape = input_shape )\n",
    "    x = Kl.Dense( 36, **layer_opts) (input_layer)\n",
    "    x = Kl.Dense( 48, **layer_opts) (x)\n",
    "    y_pred = Kl.Dense( 1., activation = 'sigmoid', name = \"OutputLayer\" )(x)\n",
    "    model = Km.Model(inputs= [input_layer, Dphi_and_weight], outputs=y_pred)\n",
    "    model_optimizer = Adam(lr=0.0001)\n",
    "    model_disco = Loss_Disco(Dphi_and_weight, 0.1)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(),loss=model_disco, metrics = ['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_Odd_Even(odd, even, n_epochs = 400, batch_size = 2000):\n",
    "    fit_history_list = []\n",
    "    model_list = []\n",
    "    input_shape = odd[0].shape[1]\n",
    "\n",
    "    lr_schedule = tf.keras.callbacks.LearningRateScheduler(lr_step_decay)\n",
    "\n",
    "    X_odd, X_val_odd, weights_odd, weights_val_odd, y_odd, y_val_odd, Dphi_odd, Dphi_val_odd = train_test_split(odd[0], odd[2], odd[1], odd[4], test_size=0.2)\n",
    "    X_even, X_val_even, weights_even, weights_val_even, y_even, y_val_even, Dphi_even, Dphi_val_even = train_test_split(even[0], even[2], even[1], even[4], test_size=0.2)\n",
    "    \n",
    "    Dphi_and_weights_odd = np.vstack([Dphi_odd, weights_odd]).T\n",
    "    Dphi_and_weights_even = np.vstack([Dphi_even, weights_even]).T\n",
    "    \n",
    "    Dphi_and_weights_odd_val = np.vstack([Dphi_val_odd, weights_val_odd]).T\n",
    "    Dphi_and_weights_even_val = np.vstack([Dphi_val_even, weights_val_even]).T\n",
    "    \n",
    "\n",
    "    test = [X_odd, Dphi_and_weights_odd]\n",
    "    print(test[0].shape)\n",
    "    print(test[1].shape)\n",
    "    \n",
    "    model_odd = Create_Model_with_Disco(input_shape)\n",
    "    model_even = Create_Model_with_Disco(input_shape)\n",
    "    fit_history_odd = model_odd.fit([X_odd, Dphi_and_weights_odd], y_odd, epochs = n_epochs, shuffle = True, batch_size = batch_size, validation_data=([X_val_odd,Dphi_and_weights_odd_val], y_val_odd, weights_val_odd), sample_weight=weights_odd, verbose=0 ,callbacks=[tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 100, verbose = True, min_delta = 0.001),lr_schedule])\n",
    "    fit_history_even = model_even.fit([X_even, Dphi_and_weights_even], y_even, epochs = n_epochs, shuffle = True, batch_size = batch_size, validation_data=([X_val_even,Dphi_and_weights_even_val], y_val_even, weights_val_even), sample_weight=weights_even, verbose=0 ,callbacks=[tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 100, verbose = True, min_delta = 0.001),lr_schedule])\n",
    "\n",
    "    return fit_history_odd, model_odd, fit_history_even, model_even"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(857245, 6)\n",
      "(857245, 2)\n",
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_32 (InputLayer)           [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 36)           252         input_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 48)           1776        dense_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_31 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "OutputLayer (Dense)             (None, 1)            49          dense_31[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,077\n",
      "Trainable params: 2,077\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_34 (InputLayer)           [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 36)           252         input_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 48)           1776        dense_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_33 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "OutputLayer (Dense)             (None, 1)            49          dense_33[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,077\n",
      "Trainable params: 2,077\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Can not squeeze dim[0], expected a dimension of 1, got 20000\n\t [[{{node loss_22/OutputLayer_loss/weighted_loss/Squeeze}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-963cd100863c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhist_odd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_odd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist_even\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_even\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrain_Odd_Even\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0modd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meven\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-36-5c5993c70890>\u001b[0m in \u001b[0;36mTrain_Odd_Even\u001b[0;34m(odd, even, n_epochs, batch_size)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mmodel_odd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCreate_Model_with_Disco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mmodel_even\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCreate_Model_with_Disco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mfit_history_odd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_odd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_odd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDphi_and_weights_odd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_odd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_val_odd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDphi_and_weights_odd_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_odd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_val_odd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights_odd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mfit_history_even\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_even\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_even\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDphi_and_weights_even\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_even\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_val_even\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDphi_and_weights_even_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_even\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_val_even\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights_even\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.local/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.local/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3956\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3957\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3958\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3959\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/.local/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1480\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1481\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1483\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Can not squeeze dim[0], expected a dimension of 1, got 20000\n\t [[{{node loss_22/OutputLayer_loss/weighted_loss/Squeeze}}]]"
     ]
    }
   ],
   "source": [
    "hist_odd, model_odd, hist_even, model_even = Train_Odd_Even(odd, even, n_epochs = n_epochs, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history_list = [hist_odd, hist_even]\n",
    "Plot_Metrics_KFold(history_list, path_tosave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Save_Model(model_odd, path_tosave, \"_odd\")\n",
    "Save_Model(model_even, path_tosave, \"_even\")\n",
    "\n",
    "pickle.dump(scaler, open(path_tosave + '/scaler.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "model_odd = Load_Model(path_tosave, name=\"_odd\")\n",
    "model_even = Load_Model(path_tosave, name=\"_even\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot_NN_Output(model_odd, odd, even, path_tosave, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Plot_NN_Output(model_even, even, odd, path_tosave, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_roc_curve(model_even, odd, path_tosave)\n",
    "plot_roc_curve(model_odd, even, path_tosave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_scores_odd = model_even.predict(odd)\n",
    "nn_scores_even = model_odd.predict(even)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "fig = plt.figure(figsize=(16,8))\n",
    "plt.grid(color='k', which='both', linestyle='--', lw=0.5, alpha=0.1, zorder = 0)\n",
    "plt.xlabel(\"NN output\", horizontalalignment='right', x=1)\n",
    "plt.xlim([0,1])\n",
    "plt.ylabel(\"Density\")\n",
    "plt.yscale('log')\n",
    "histargs = {\"bins\":40, \"range\":(0,1.), \"density\":True, \"histtype\":'step'}\n",
    "for i in range(No_Classes):\n",
    "    plt.hist(nn_scores_test[test[3]==i],label = class_names[i], **histargs)\n",
    "plt.legend(loc='upper center')\n",
    "    #plt.hist(nn_scores_test[test[1]==0][test[3]==i],label = \"Test_Background\", **histargs)\n",
    "plt.savefig(path_tosave+\"/NN_Output_Classes.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat = np.corrcoef(input_features, None, False)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,12)\n",
    "sns.heatmap(corr_mat, annot=True, cmap=\"viridis\", xticklabels=feature_names, yticklabels=feature_names, fmt=\".2f\")\n",
    "plt.savefig(path_tosave+\"/Corr_Mat.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calc Signal cut for desired Singal Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Sig = nn_scores_odd[odd[1]==1]\n",
    "Bkg = nn_scores_odd[odd[1]==0]\n",
    "Sig_Eff, Bkg_Eff, Signal_Cut = Find_Eff_Cut(Sig=Sig, Bkg=Bkg, Signal_Eff=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, g = get_feature_importance(even, model_odd, Signal_Cut, 1)\n",
    "idx = np.argsort(f)\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "ax.barh(range(even[0].shape[1]), np.sort(f), xerr=np.array(g)[idx], color=\"r\", alpha=0.7, ecolor='black', capsize=10)\n",
    "ax.set_yticks(range(even[0].shape[1]), np.array(feature_names)[idx])\n",
    "ax.set_xlabel('Feature Importance')\n",
    "plt.savefig(path_tosave + \"/Feature_Importance_even.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, g = get_feature_importance(odd, model_even, Signal_Cut, 1)\n",
    "idx = np.argsort(f)\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "ax.barh(range(even[0].shape[1]), np.sort(f), xerr=np.array(g)[idx], color=\"r\", alpha=0.7, ecolor='black', capsize=10)\n",
    "ax.set_yticks(range(even[0].shape[1]), np.array(feature_names)[idx])\n",
    "ax.set_xlabel('Feature Importance')\n",
    "plt.savefig(path_tosave + \"/Feature_Importance_odd.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sig = nn_scores_even[even[1]==1]\n",
    "Bkg = nn_scores_even[even[1]==0]\n",
    "Sig_Eff, Bkg_Eff, Signal_Cut_even = Find_Eff_Cut(Sig=Sig, Bkg=Bkg, Signal_Eff=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Make_Confusion_Matrix(even, nn_scores_even, Signal_Cut_even, class_names, path_tosave, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Make_Confusion_Matrix(even, nn_scores_even, Signal_Cut_even, class_names, path_tosave, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Make_Confusion_Matrix(odd, nn_scores_odd, Signal_Cut, class_names, path_tosave, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Make_Confusion_Matrix(odd, nn_scores_odd, Signal_Cut, class_names, path_tosave, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
